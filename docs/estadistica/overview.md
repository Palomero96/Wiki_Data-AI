# üìä Estad√≠stica para Ciencia de Datos e IA

## Tabla de Contenidos

- [Fundamentos de Estad√≠stica](#fundamentos-de-estad√≠stica)
- [Tipos de Datos y Variables](#tipos-de-datos-y-variables)
- [Estad√≠stica Descriptiva](#estad√≠stica-descriptiva)
- [Probabilidad y Distribuciones](#probabilidad-y-distribuciones)
- [Inferencia Estad√≠stica](#inferencia-estad√≠stica)
- [Regresi√≥n y Correlaci√≥n](#regresi√≥n-y-correlaci√≥n)
- [An√°lisis Multivariante](#an√°lisis-multivariante)
- [Estad√≠stica Computacional](#estad√≠stica-computacional)
- [Aplicaciones en IA y Machine Learning](#aplicaciones-en-ia-y-machine-learning)

## Fundamentos de Estad√≠stica

### ¬øQu√© es la Estad√≠stica?
Ciencia que permite aprender de los datos mediante:
- Dise√±o de estudios
- Recogida de datos
- An√°lisis e interpretaci√≥n
- Organizaci√≥n y visualizaci√≥n
- Conclusiones y predicciones

### Tipos de Estad√≠stica
- **Descriptiva**: Describe y resume datos muestrales
- **Inferencial**: Extrae conclusiones sobre poblaciones

### Conceptos Clave
- **Poblaci√≥n**: Conjunto completo de individuos
- **Muestra**: Subconjunto representativo
- **Muestreo**: Proceso de selecci√≥n de muestra
- **Inferencia**: Extrapolaci√≥n de muestra a poblaci√≥n

## Tipos de Datos y Variables

### Variables Categ√≥ricas
- **Nominales**: Sin orden inherente (g√©nero, color)
- **Ordinales**: Con orden natural (nivel educativo, satisfacci√≥n)

### Variables Cuantitativas
- **Discretas**: Valores enteros (n√∫mero de hijos, conteos)
- **Continuas**: Cualquier valor en un rango (peso, temperatura)

### Clasificaci√≥n por Rol
- **Variable respuesta/dependiente**: Lo que queremos predecir
- **Variable explicativa/independiente**: Lo que usamos para predecir
- **Variables intermediarias**: No medidas pero influyentes

## Estad√≠stica Descriptiva

### Medidas de Tendencia Central
| Medida | F√≥rmula | Ventajas | Desventajas |
|--------|---------|----------|-------------|
| **Media** | $\bar{x} = \frac{\sum x_i}{n}$ | Usa todos los datos | Sensible a outliers |
| **Mediana** | Valor central ordenado | Robusta a outliers | No usa toda la informaci√≥n |
| **Moda** | Valor m√°s frecuente | √ötil para categ√≥ricas | Puede haber m√∫ltiples modas |

### Medidas de Dispersi√≥n
- **Rango**: Diferencia entre m√°ximo y m√≠nimo
- **Varianza**: $\sigma^2 = \frac{\sum (x_i - \bar{x})^2}{n}$
- **Desviaci√≥n Est√°ndar**: $\sigma = \sqrt{\sigma^2}$
- **Coeficiente de Variaci√≥n**: $CV = \frac{\sigma}{\bar{x}}$

### Medidas Robustas
- **Media recortada**: Elimina outliers extremos
- **Media winsorizada**: Reemplaza outliers con valores l√≠mite
- **Rango intercuart√≠lico**: IQR = Q3 - Q1

### Visualizaci√≥n de Datos
```python
# Gr√°ficos comunes en Python
import matplotlib.pyplot as plt
import seaborn as sns

# Histograma
plt.hist(data, bins=30)

# Boxplot
sns.boxplot(x=data)

# Scatterplot
plt.scplot(x_var, y_var)
```

## Probabilidad y Distribuciones

### Conceptos B√°sicos
- **Probabilidad**: Medida de incertidumbre (0-1)
- **Espacio muestral**: Todos los resultados posibles
- **Variable aleatoria**: Funci√≥n que asigna valores a resultados

### Distribuciones Discretas
- **Binomial**: $P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}$
- **Poisson**: $P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!}$
- **Geom√©trica**: N√∫mero de intentos hasta el primer √©xito

### Distribuciones Continuas
- **Normal**: $f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
- **Exponencial**: Modela tiempos entre eventos
- **Uniforme**: Todos los valores igualmente probables

### Teorema del L√≠mite Central
Cuando n ‚Üí ‚àû, la distribuci√≥n de las medias muestrales:
- Se aproxima a una normal
- Media = media poblacional
- Desviaci√≥n = œÉ/‚àön

## Inferencia Estad√≠stica

### Estimaci√≥n
- **Puntual**: Valor √∫nico (media muestral)
- **Por intervalos**: Rango de valores plausibles

### Intervalos de Confianza
- **IC 95%**: $\bar{x} \pm 1.96 \frac{\sigma}{\sqrt{n}}$
- **Margen de error**: $z_{\alpha/2} \frac{\sigma}{\sqrt{n}}$

### Contrastes de Hip√≥tesis
- **H‚ÇÄ**: Hip√≥tesis nula (status quo)
- **H‚ÇÅ**: Hip√≥tesis alternativa (lo que queremos probar)
- **Valor p**: Probabilidad de obtener resultados tan extremos si H‚ÇÄ es verdadera
- **Œ±**: Nivel de significaci√≥n (usualmente 0.05)
- **Regi√≥n de rechazo**: Valores que llevan a rechazar H‚ÇÄ

### Errores
| | H‚ÇÄ Verdadera | H‚ÇÄ Falsa |
|---|---|---|
| **Rechazar H‚ÇÄ** | Error Tipo I (Œ±) | Decisi√≥n correcta (1-Œ≤) |
| **No rechazar H‚ÇÄ** | Decisi√≥n correcta | Error Tipo II (Œ≤) |

## Regresi√≥n y Correlaci√≥n

### Correlaci√≥n
- **Pearson**: $r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2 \sum (y_i - \bar{y})^2}}$
- Valores entre -1 y 1
- Mide fuerza y direcci√≥n de relaci√≥n lineal

### Regresi√≥n Lineal
```python
# Modelo lineal
from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X, y)
y_pred = model.predict(X)
``` 

### Supuestos del Modelo

* Linealidad
* Independencia de errores
* Homocedasticidad (varianza constante)
* Normalidad de residuos

### Diagn√≥stico del Modelo

* Residuos vs Ajustados: Patr√≥n aleatorio
* QQ-plot: Normalidad de residuos
* Leverage y outliers: Puntos influyentes

## An√°lisis Multivariante

#### An√°lisis de Componentes Principales (PCA)

```python
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
```

* Reduce dimensionalidad
* Maximiza varianza explicada
* Componentes ortogonales

## An√°lisis Cluster

* K-means: Agrupamiento por distancia
* Jer√°rquico: Dendrogramas
* DBSCAN: Basado en densidad

## An√°lisis Factorial

* Identifica variables latentes
* Reduce n√∫mero de variables
* Interpreta estructura subyacente

# Estad√≠stica Computacional

## Herramientas

* R: Especializado en an√°lisis estad√≠stico
* Python: Vers√°til para ciencia de datos
* SQL: Manipulaci√≥n de bases de datos

## Ventajas de R

* Amplio ecosistema de paquetes estad√≠sticos
* Excelentes capacidades de visualizaci√≥n
* Comunidad activa en estad√≠stica
* Reproducibilidad con RMarkdown

# Big Data y Estad√≠stica

## Desaf√≠os

* Almacenamiento y acceso eficiente
* Procesamiento distribuido
* Algoritmos escalables
* Quality assurance de datos

## Soluciones

* Apache Spark
* Hadoop
* Bases de datos distribuidas
* Computaci√≥n en cloud

## Aplicaciones en IA y Machine Learning

### Relaci√≥n Estad√≠stica-ML

* Estad√≠stica: Inferencia, significancia, incertidumbre
* ML: Predicci√≥n, escalabilidad, automatizaci√≥n

### Conceptos Clave en ML

* Bias-Variance Tradeoff

  * High bias: Subajuste (underfitting)
  * High variance: Sobreajuste (overfitting)
* Cross-validation

  * K-fold validation
  * Train-test splits
* Hyperparameter tuning
* Regularization

  * L1 (Lasso): Selecci√≥n de caracter√≠sticas
  * L2 (Ridge): Reducci√≥n de sobreajuste

### M√©tricas de Evaluaci√≥n

| Tipo          | M√©tricas                                 |
| ------------- | ---------------------------------------- |
| Clasificaci√≥n | Accuracy, Precision, Recall, F1, AUC-ROC |
| Regresi√≥n     | MSE, MAE, R¬≤, RMSE                       |
| Clustering    | Silhouette score, Davies-Bouldin         |

### Bayesian Statistics in AI

* Naive Bayes: Clasificaci√≥n probabil√≠stica
* Bayesian Networks: Modelos gr√°ficos probabil√≠sticos
* MCMC: Muestreo de distribuciones complejas

### Deep Learning Statistics

* Initialization: Xavier, He initialization
* Normalization: Batch norm, layer norm
* Uncertainty: Bayesian neural networks
* Regularization: Dropout, weight decay

## Buenas Pr√°cticas

### An√°lisis Exploratorio (EDA)

* Comprensi√≥n de datos: Forma, tipos, valores missing
* Limpieza: Outliers, missing values, transformaciones
* Visualizaci√≥n: Distribuciones, correlaciones, patrones
* Feature engineering: Creaci√≥n de variables relevantes

### Validaci√≥n de Modelos

* Train/Test split: 70-30 o 80-20
* Cross-validation: K-fold (usualmente 5 o 10)
* Time-series validation: Walk-forward testing
* External validation: Datos completamente nuevos

### √âtica y Sesgos

* Fairness: Mitigaci√≥n de sesgos algor√≠tmicos
* Transparency: Modelos interpretables
* Privacy: Protecci√≥n de datos sensibles
* Accountability: Responsabilidad en decisiones automatizadas

## Recursos y Herramientas

### Librer√≠as Python

```python
# An√°lisis estad√≠stico
import scipy.stats as stats
import statsmodels.api as sm

# Machine learning
from sklearn import linear_model, ensemble, model_selection

# Visualizaci√≥n
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
```

### Librer√≠as R

```r
# An√°lisis b√°sico
library(tidyverse)
library(ggplot2)

# Modelado avanzado
library(caret)
library(randomForest)
library(xgboost)

# Series temporales
library(forecast)
library(tseries)
```


## Conclusi√≥n

La estad√≠stica proporciona los fundamentos matem√°ticos y metodol√≥gicos esenciales para la ciencia de datos e inteligencia artificial. Dominar estos conceptos permite:

* Dise√±ar mejores experimentos y recoger datos de calidad
* Entender profundamente los datos mediante EDA
* Construir modelos robustos con validaci√≥n adecuada
* Interpretar resultados con rigor estad√≠stico
* Comunicar hallazgos con claridad y precisi√≥n
* Tomar decisiones basadas en evidencia s√≥lida
