# Algoritmos de Aprendizaje No Supervisado

El **aprendizaje no supervisado** se centra en encontrar patrones, estructuras o representaciones en datos **sin etiquetas conocidas**. Sus principales aplicaciones incluyen **clustering, reducci√≥n de dimensionalidad, generaci√≥n de datos y detecci√≥n de anomal√≠as**.

---

## 1. Clustering

Agrupa los datos seg√∫n similitud, creando **clusters naturales**.

### 1.1 K-Means

* **Objetivo**: Particionar datos en k clusters minimizando la suma de distancias cuadradas.
* **F√≥rmula de centroide**:
$$
c_j = \frac{1}{|C_j|} \sum_{x_i \in C_j} x_i
$$
* **Ventajas**: Simple y eficiente.
* **Limitaciones**: Sensible a outliers y requiere definir k.

### 1.2 DBSCAN

* **Objetivo**: Formar clusters de alta densidad y detectar outliers.
* **Par√°metros clave**: *eps* (radio de vecindad), *minPts* (m√≠nimo de puntos por cluster).
* **Ventajas**: Detecta clusters de forma arbitraria; no requiere k.
* **Limitaciones**: Sensible a par√°metros y densidades desiguales.

### 1.3 Expectation-Maximization (EM)

* **Objetivo**: Modelar datos como mezcla de distribuciones (normalmente Gaussianas).
* **Funcionamiento**:
  1. Inicializa par√°metros de las distribuciones.
  2. Expectation: calcula probabilidades de pertenencia.
  3. Maximization: ajusta par√°metros para maximizar likelihood.
* **Ventajas**: Probabil√≠stico, flexible.
* **Limitaciones**: Puede converger a √≥ptimos locales.

### 1.4 Fuzzy C-Means

* **Objetivo**: Cada punto pertenece a m√∫ltiples clusters con diferentes grados de pertenencia.
* **F√≥rmula de actualizaci√≥n de pertenencia**:
$$
u_{ij} = \frac{1}{\sum_{k=1}^c \left(\frac{\|x_i - c_j\|}{\|x_i - c_k\|}\right)^{\frac{2}{m-1}}}
$$
* **Ventajas**: Maneja ambig√ºedad en clusters.
* **Limitaciones**: M√°s costoso computacionalmente; requiere definir c y m.

### 1.5 Clustering Jer√°rquico

* **Objetivo**: Crear √°rbol de clusters (*dendrograma*).
* **Tipos**: Aglomerativo y divisivo.
* **Ventajas**: No requiere n√∫mero de clusters inicial; √∫til para visualizaci√≥n.
* **Limitaciones**: Computacionalmente costoso.

---

## 2. Deep Learning No Supervisado

Se enfoca en **representaci√≥n de datos y generaci√≥n de muestras nuevas**.

### 2.1 Autoencoders

* **Objetivo**: Aprender una representaci√≥n comprimida de los datos.
* **Arquitectura**: Encoder ‚Üí Latent space ‚Üí Decoder.
* **Funci√≥n de p√©rdida t√≠pica**:
$$
L = \frac{1}{n} \sum_{i=1}^n \|x_i - \hat{x}_i\|^2
$$
* **Aplicaciones**: Reducci√≥n de dimensionalidad, denoising, generaci√≥n.

### 2.2 Generative Adversarial Networks (GANs)

* **Objetivo**: Generar datos sint√©ticos que imiten la distribuci√≥n real.
* **Funcionamiento**:
  - **Generador (G)**: crea muestras falsas.
  - **Discriminador (D)**: distingue reales de falsas.
* **Funci√≥n de p√©rdida (minimax)**:
$$
\min_G \max_D V(D,G) = \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1-D(G(z)))]
$$
* **Aplicaciones**: Imagen, video, datos sint√©ticos.

---

## 3. Aprendizaje por Refuerzo (RL) ‚Äì Contexto

Aunque RL puede considerarse **semi-supervisado**, comparte conceptos con no supervisado en exploraci√≥n de entornos.

### 3.1 Q-Learning

* **Objetivo**: Aprender pol√≠tica √≥ptima mediante tabla Q(s,a).
* **Actualizaci√≥n de Q**:
$$
Q(s,a) \leftarrow Q(s,a) + \alpha \left[r + \gamma \max_{a'} Q(s',a') - Q(s,a)\right]
$$

### 3.2 SARSA

* **Objetivo**: Similar a Q-Learning, pero actualiza Q usando la acci√≥n realmente tomada.
* **F√≥rmula de actualizaci√≥n**:
$$
Q(s,a) \leftarrow Q(s,a) + \alpha \left[r + \gamma Q(s',a') - Q(s,a)\right]
$$

### 3.3 Deep Reinforcement Learning

* **Objetivo**: Usar redes neuronales profundas para aproximar funciones Q o pol√≠ticas.
* **Ventajas**: Maneja espacios de estados grandes o continuos.
* **Aplicaciones**: Videojuegos, robots, control aut√≥nomo.

---

## üìå Conclusi√≥n

El aprendizaje no supervisado incluye:

* **Clustering**: Descubrir grupos naturales (K-Means, DBSCAN, EM, Fuzzy C-Means, jer√°rquicos).
* **Deep Learning**: Aprender representaciones o generar datos (Autoencoders, GANs).
* **Reinforcement Learning**: Explorar entornos y optimizar pol√≠ticas (Q-Learning, SARSA, Deep RL).

La elecci√≥n del algoritmo depende de:

* Tipo de datos y dimensionalidad.
* Necesidad de interpretaci√≥n vs generaci√≥n de datos.
* Presencia de ruido o outliers.
* Requerimientos computacionales y escalabilidad.
