# Evaluaci贸n de Algoritmos de Aprendizaje No Supervisado

La **evaluaci贸n de modelos no supervisados** es m谩s compleja que en supervisado, ya que no hay etiquetas conocidas para comparar. Se centra en medir **coherencia interna**, **estructura encontrada** y, cuando es posible, comparaci贸n con datos externos.

---

## 1. Validaci贸n de Modelos

### 1.1 Evaluaci贸n Interna

* Se basa en **propiedades de los datos y clusters** detectados.
* No requiere etiquetas externas.
* Ejemplos de m茅tricas internas: **Silhouette, Davies-Bouldin, Calinski-Harabasz**.

### 1.2 Evaluaci贸n Externa

* Compara los resultados del clustering con **etiquetas verdaderas**, si se disponen.
* til para datasets de prueba o benchmarking.
* M茅tricas comunes: **Adjusted Rand Index (ARI), Normalized Mutual Information (NMI)**.

### 1.3 Validaci贸n por Estabilidad

* Se entrena el modelo varias veces con **submuestras** de los datos o con **distintas inicializaciones**.
* Mide si los resultados son **consistentes**.
* Indicador de robustez del algoritmo.

---

## 2. M茅tricas de Clustering

### 2.1 Silhouette Score

Mide **qu茅 tan similar es un punto a su propio cluster comparado con otros clusters**.

$$
s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
$$

* \(a(i)\): distancia promedio a puntos del mismo cluster.
* \(b(i)\): distancia m铆nima promedio a puntos de otros clusters.
* Rango: -1 a 1. Cercano a 1 = buen cluster, cercano a 0 = punto entre clusters, negativo = posible error.

### 2.2 Davies-Bouldin Index

Eval煤a **similitud entre clusters**, penalizando clusters cercanos entre s铆.

$$
DB = \frac{1}{k} \sum_{i=1}^k \max_{j \neq i} \left( \frac{\sigma_i + \sigma_j}{d(c_i, c_j)} \right)
$$

* \( \sigma_i \): dispersi贸n del cluster i.
* \( d(c_i, c_j) \): distancia entre centroides de clusters i y j.
* Menor valor = mejor separaci贸n entre clusters.

### 2.3 Calinski-Harabasz Index

Relaci贸n entre **dispersi贸n entre clusters y dentro de clusters**.

$$
CH = \frac{Tr(B_k)}{Tr(W_k)} \cdot \frac{n-k}{k-1}
$$

* \(Tr(B_k)\): traza de la matriz de dispersi贸n entre clusters.
* \(Tr(W_k)\): traza de la matriz de dispersi贸n dentro de clusters.
* \(n\): n煤mero de puntos, \(k\): n煤mero de clusters.
* Mayor valor = mejor definici贸n de clusters.

---

## 3. M茅tricas de Comparaci贸n Externa (si hay etiquetas)

### 3.1 Adjusted Rand Index (ARI)

Mide **similitud entre dos agrupamientos** ajustando por azar.

$$
ARI = \frac{RI - \mathbb{E}[RI]}{\max(RI) - \mathbb{E}[RI]}
$$

* RI: Rand Index (fracci贸n de pares de puntos correctamente agrupados o separados).
* Rango: -1 a 1. 1 = coincidencia perfecta.

### 3.2 Normalized Mutual Information (NMI)

Mide **informaci贸n compartida entre clustering y etiquetas reales**.

$$
NMI(U,V) = \frac{2 \cdot I(U;V)}{H(U) + H(V)}
$$

* \(I(U;V)\): informaci贸n mutua.
* \(H(U), H(V)\): entrop铆as de los clusterings.
* Rango: 0 a 1. 1 = coincidencia perfecta.

---

## 4. Problemas Comunes

### 4.1 Determinar el N煤mero de Clusters

* Elegir k incorrecto puede generar **clusters artificiales**.
* M茅todos: **codo (Elbow), silhouette, gap statistic**.

### 4.2 Sensibilidad a Escala y Preprocesamiento

* Algoritmos como k-means dependen de **distancias**, sensibles a escalas diferentes.
* Soluci贸n: **normalizar o estandarizar** datos.

### 4.3 Puntos At铆picos (Outliers)

* Pueden **distorsionar centroides o densidades**.
* Soluciones: detectar y eliminar outliers o usar algoritmos robustos (DBSCAN, HDBSCAN).

### 4.4 Inicializaci贸n Aleatoria

* k-means y otros algoritmos sensibles a la **semilla inicial**.
* Soluci贸n: ejecutar m煤ltiples veces y elegir mejor resultado seg煤n m茅trica interna.

---

##  Conclusi贸n

La evaluaci贸n de algoritmos no supervisados requiere:

* **M茅tricas internas** para analizar cohesi贸n y separaci贸n.
* **M茅tricas externas** si existen etiquetas.
* **Validaci贸n de estabilidad** para asegurar consistencia.
* Uso combinado de m茅tricas y visualizaci贸n (t-SNE, PCA) ayuda a interpretar resultados.

Una buena pr谩ctica es **probar varios algoritmos, variar par谩metros y combinar m茅tricas** para obtener una visi贸n completa del desempe帽o.
